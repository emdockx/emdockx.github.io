##########
# -
# -
# -
# Load packages
suppressPackageStartupMessages({
library(dplyr)
library(jsonlite)
library(httr)
library(ggplot2)
library(stringr)
library(tidyr)
library(purrr)
library(lubridate)
library(leaflet)
library(DT)
library(plotly)
library(openmeteo)
library(RColorBrewer)
})
# Prepare global environment
rm(list = ls(all = TRUE))
# Load existing data
#load("/Users/emmanueldockx/Dropbox/GitHub/emdockx.github.io/stravawattz.RData")
##================================================================
##================================================================
## SECTION 1: API and cleaning
##================================================================
##================================================================
# DEBUGGING
#df_running <- df_running[0, ]
#df_cycling <- df_cycling[0, ]
#df_swimming <- df_swimming[0, ]
#rm(list=setdiff(ls(), c("df_running", "df_cycling", "df_swimming")))
# Define Strava API credentials
STRAVA_KEY <- "113481"
STRAVA_SECRET <- "0195b39449a08d472051129f877d8279dfeeaaf7"
# Create an OAuth app
app <- oauth_app("strava", STRAVA_KEY, STRAVA_SECRET)
# Define the OAuth endpoints
endpoint <- oauth_endpoint(
request = NULL,
authorize = "https://www.strava.com/oauth/authorize",
access = "https://www.strava.com/oauth/token"
)
# Get an OAuth token
token <- oauth2.0_token(endpoint, app, as_header = FALSE, scope = "activity:read_all")
# Capture access token
access_token <- token$credentials$access_token
# Initialize empty dataframe
df <- data.frame()
# Initialize page variable
page <- 1
# Start data retrieval
while (TRUE) {
req <- httr::GET(
url = "https://www.strava.com/api/v3/athlete/activities",
config = token,
query = list(per_page = 200, page = page)
)
# Convert JSON to dataframe
activity_data <- fromJSON(content(req, as = "text"), flatten = TRUE)
# Stop if no data found
if (length(activity_data) == 0) {break}
# Append data while ensuring all columns are kept
df <- bind_rows(df, activity_data)
# Turn to next page
page <- page + 1
}
View(df)
# Clean global environment
suppressWarnings({rm(app, endpoint, req, token, i, activity_data, common_cols, page, STRAVA_KEY, STRAVA_SECRET)})
View(df)
# Proceed only if new data was found
if (nrow(df) >= 1) {
# Initialize empty geo column
df$geo <- NA
# Check each session for geo data
for (i in unique(df$id)){
temp <- df |> filter(id == i)
df$geo[match(i, df$id)] <- ifelse(any(sapply(temp$start_latlng, function(x) length(x) > 0)) == TRUE, 1, 0)}
# Filter and convert the raw data
df_clean <- df |>
select(id, date = start_date, type = sport_type, distance, time = moving_time, elevation = total_elevation_gain, speed_max = max_speed, hr = average_heartrate, hrmax = max_heartrate, geo) |>
mutate(date = as.Date(date), distance = round(distance, 0), time = round(time, 99), speed_max = speed_max * 3.6, hr = round(hr, 0), hrmax = round(hrmax, 0)) |>
arrange(date, id, type, distance, time, elevation, hr)
# Cancel if no new data was found
} else {"No new Strava data found."}
# Clean global environment
rm(df, temp, i)
View(df_clean)
# Subset data
df_clean_running <- df_clean |> filter(type == "Run")
# Cleaning for RUNNING dataframe
df_clean_running <- df_clean_running |>
filter(geo == 1) |> # only when microdata is available
#filter(distance >= 1000) |> # only sessions with at least 1000m running
#filter(time >= 600) |> # only sessions with at least 10min running
filter(!is.na(hr)) |> # only sessions with non-missing HR data
arrange(id) # sort by id number
# Add data for speed (km/h)
df_clean_running$speed <- round((df_clean_running$distance/1000) / (df_clean_running$time/60/60), 2)
# Subset data
df_clean_running <- df_clean |> filter(type == "Run")
# Cleaning for RUNNING dataframe
df_clean_running <- df_clean_running |>
filter(geo == 1) |> # only when microdata is available
#filter(distance >= 1000) |> # only sessions with at least 1000m running
#filter(time >= 600) |> # only sessions with at least 10min running
filter(!is.na(hr)) |> # only sessions with non-missing HR data
arrange(id) # sort by id number
##================================================================
##================================================================
## SECTION 0: Preparation
##================================================================
##================================================================
##########
## TODO ##
##########
# -
# -
# -
# Load packages
suppressPackageStartupMessages({
library(dplyr)
library(jsonlite)
library(httr)
library(ggplot2)
library(stringr)
library(tidyr)
library(purrr)
library(lubridate)
library(leaflet)
library(DT)
library(plotly)
library(openmeteo)
library(RColorBrewer)
})
# Prepare global environment
rm(list = ls(all = TRUE))
# Load existing data
#load("/Users/emmanueldockx/Dropbox/GitHub/emdockx.github.io/stravawattz.RData")
##================================================================
##================================================================
## SECTION 1: API and cleaning
##================================================================
##================================================================
# DEBUGGING
#df_running <- df_running[0, ]
#df_cycling <- df_cycling[0, ]
#df_swimming <- df_swimming[0, ]
#rm(list=setdiff(ls(), c("df_running", "df_cycling", "df_swimming")))
# Define Strava API credentials
STRAVA_KEY <- "113481"
STRAVA_SECRET <- "0195b39449a08d472051129f877d8279dfeeaaf7"
# Create an OAuth app
app <- oauth_app("strava", STRAVA_KEY, STRAVA_SECRET)
# Define the OAuth endpoints
endpoint <- oauth_endpoint(
request = NULL,
authorize = "https://www.strava.com/oauth/authorize",
access = "https://www.strava.com/oauth/token"
)
# Get an OAuth token
token <- oauth2.0_token(endpoint, app, as_header = FALSE, scope = "activity:read_all")
# Capture access token
access_token <- token$credentials$access_token
# Initialize empty dataframe
df <- data.frame()
# Initialize page variable
page <- 1
# Start data retrieval
while (TRUE) {
req <- httr::GET(
url = "https://www.strava.com/api/v3/athlete/activities",
config = token,
query = list(per_page = 200, page = page)
)
# Convert JSON to dataframe
activity_data <- fromJSON(content(req, as = "text"), flatten = TRUE)
# Stop if no data found
if (length(activity_data) == 0) {break}
# Append data while ensuring all columns are kept
df <- bind_rows(df, activity_data)
# Turn to next page
page <- page + 1
}
# Clean global environment
suppressWarnings({rm(app, endpoint, req, token, i, activity_data, common_cols, page, STRAVA_KEY, STRAVA_SECRET)})
# Determine useful existing data id's
#saved_id <- unique(c(df_running$id, df_cycling$id, df_swimming$id))
# Remove existing data
#df <- df |> filter(!(id %in% saved_id))
# Hier komt nog procedure om onnuttige id's op te slagen
# Proceed only if new data was found
if (nrow(df) >= 1) {
# Initialize empty geo column
df$geo <- NA
# Check each session for geo data
for (i in unique(df$id)){
temp <- df |> filter(id == i)
df$geo[match(i, df$id)] <- ifelse(any(sapply(temp$start_latlng, function(x) length(x) > 0)) == TRUE, 1, 0)}
# Filter and convert the raw data
df_clean <- df |>
select(id, date = start_date, type = sport_type, distance, time = moving_time, elevation = total_elevation_gain, average_speed, speed_max = max_speed, hr = average_heartrate, hrmax = max_heartrate, geo) |>
mutate(date = as.Date(date), distance = round(distance, 0), time = round(time, 99), speed_max = speed_max * 3.6, hr = round(hr, 0), hrmax = round(hrmax, 0)) |>
arrange(date, id, type, distance, time, elevation, hr)
# Cancel if no new data was found
} else {"No new Strava data found."}
# Clean global environment
View(df)
# Proceed only if new data was found
if (nrow(df) >= 1) {
# Initialize empty geo column
df$geo <- NA
# Check each session for geo data
for (i in unique(df$id)){
temp <- df |> filter(id == i)
df$geo[match(i, df$id)] <- ifelse(any(sapply(temp$start_latlng, function(x) length(x) > 0)) == TRUE, 1, 0)}
# Filter and convert the raw data
df_clean <- df |>
select(id, date = start_date, type = sport_type, distance, time = moving_time, elevation = total_elevation_gain, speed = average_speed, speed_max = max_speed, hr = average_heartrate, hr_max = max_heartrate, geo) |>
mutate(date = as.Date(date), distance = round(distance, 0), time = round(time, 99), speed_max = speed_max * 3.6, hr = round(hr, 0), hr_max = round(hrmax, 0)) |>
arrange(date, id, type, distance, time, elevation, hr)
# Cancel if no new data was found
} else {"No new Strava data found."}
# Proceed only if new data was found
if (nrow(df) >= 1) {
# Initialize empty geo column
df$geo <- NA
# Check each session for geo data
for (i in unique(df$id)){
temp <- df |> filter(id == i)
df$geo[match(i, df$id)] <- ifelse(any(sapply(temp$start_latlng, function(x) length(x) > 0)) == TRUE, 1, 0)}
# Filter and convert the raw data
df_clean <- df |>
select(id, date = start_date, type = sport_type, distance, time = moving_time, elevation = total_elevation_gain, speed = average_speed, speed_max = max_speed, hr = average_heartrate, hr_max = max_heartrate, geo) |>
mutate(date = as.Date(date), distance = round(distance, 0), time = round(time, 99), speed_max = speed_max * 3.6, hr = round(hr, 0), hr_max = round(hr_max, 0)) |>
arrange(date, id, type, distance, time, elevation, hr)
# Cancel if no new data was found
} else {"No new Strava data found."}
# Subset data
df_clean_running <- df_clean |> filter(type == "Run")
# Cleaning for RUNNING dataframe
df_clean_running <- df_clean_running |>
filter(geo == 1) |> # only when microdata is available
#filter(distance >= 1000) |> # only sessions with at least 1000m running
#filter(time >= 600) |> # only sessions with at least 10min running
filter(!is.na(hr)) |> # only sessions with non-missing HR data
arrange(id) # sort by id number
df_new <- df[!(df$id %in% unique(df_clean_running$id)), ]
View(df_new)
#DEBUGGING
df_copy <- df
# Remove valid running sessions from df
df <- df[!(df$id %in% unique(df_clean_running$id)), ]
rm(df_new)
View(df)
View(df_clean)
View(df_clean_running)
# Add data for speed (km/h)
df_clean_running$speed2 <- round((df_clean_running$distance/1000) / (df_clean_running$time/60/60), 2)
df_clean_running$speed3 <- df_clean_running$speed * 3.6
# Subset data
df_clean_running <- df_clean |> filter(type == "Run")
# Cleaning for RUNNING dataframe
df_clean_running <- df_clean_running |>
filter(geo == 1) |> # only when microdata is available
#filter(distance >= 1000) |> # only sessions with at least 1000m running
#filter(time >= 600) |> # only sessions with at least 10min running
filter(!is.na(hr)) |> # only sessions with non-missing HR data
arrange(id) # sort by id number
# Remove valid running sessions from df
df <- df[!(df$id %in% unique(df_clean_running$id)), ]
# Convert speed from meter-per-second to kilometer-per-hour
df_clean_running$speed <- round(df_clean_running$speed * 3.6, 4)
# Convert speed (km/h) to pace (min/km)
df_clean_running$pace <- round((df_clean_running$time/60) / (df_clean_running$distance/1000), 2)
# Convert speed (km/h) to pace (min/km)
df_clean_running$pace <- round((df_clean_running$time/60) / (df_clean_running$distance/1000), 2)
df_clean_running$pace2 <- 60 / df_clean_running$speed
View(df_clean_running)
# Subset data
df_clean_running <- df_clean |> filter(type == "Run")
# Cleaning for RUNNING dataframe
df_clean_running <- df_clean_running |>
filter(geo == 1) |> # only when microdata is available
#filter(distance >= 1000) |> # only sessions with at least 1000m running
#filter(time >= 600) |> # only sessions with at least 10min running
filter(!is.na(hr)) |> # only sessions with non-missing HR data
arrange(id) # sort by id number
# Remove valid running sessions from df
df <- df[!(df$id %in% unique(df_clean_running$id)), ]
# Convert speed from meter-per-second to kilometer-per-hour
df_clean_running$speed <- round(df_clean_running$speed * 3.6, 4)
# Convert speed (km/h) to pace (min/km)
df_clean_running$pace <- round(60 / df_clean_running$speed, 4)
# Convert speed_max from meter-per-second to kilometer-per-hour
df_clean_running$speed_max <- round(df_clean_running$speed_max * 3.6, 4)
# Correction for max running speeds (remove the difference between speed and speed_max by half)
df_clean_running <- df_clean_running |> mutate(speed_max = speed_max - abs(speed - speed_max) * 0.5)
# Convert speed_max (km/h) to pace_max (min/km)
df_clean_running$pace_max <- 60 / df_clean_running$speed_max
# Subset data
df_clean_running <- df_clean |> filter(type == "Run")
# Cleaning for RUNNING dataframe
df_clean_running <- df_clean_running |>
filter(geo == 1) |> # only when microdata is available
#filter(distance >= 1000) |> # only sessions with at least 1000m running
#filter(time >= 600) |> # only sessions with at least 10min running
filter(!is.na(hr)) |> # only sessions with non-missing HR data
arrange(id) # sort by id number
# Remove valid running sessions from df
df <- df[!(df$id %in% unique(df_clean_running$id)), ]
# Convert speed from meter-per-second to kilometer-per-hour
df_clean_running$speed <- round(df_clean_running$speed * 3.6, 4)
# Convert speed (km/h) to pace (min/km)
df_clean_running$pace <- round(60 / df_clean_running$speed, 4)
# Convert speed_max from meter-per-second to kilometer-per-hour
df_clean_running$speed_max <- round(df_clean_running$speed_max * 3.6, 4)
df$max_speed <- df$max_speed / 3.6
df_clean$max_speed <- df_clean$max_speed / 3.6
# Subset data
df_clean_running <- df_clean |> filter(type == "Run")
# Cleaning for RUNNING dataframe
df_clean_running <- df_clean_running |>
filter(geo == 1) |> # only when microdata is available
#filter(distance >= 1000) |> # only sessions with at least 1000m running
#filter(time >= 600) |> # only sessions with at least 10min running
filter(!is.na(hr)) |> # only sessions with non-missing HR data
arrange(id) # sort by id number
# Remove valid running sessions from df
df <- df[!(df$id %in% unique(df_clean_running$id)), ]
# Convert speed from meter-per-second to kilometer-per-hour
df_clean_running$speed <- round(df_clean_running$speed * 3.6, 4)
# Convert speed (km/h) to pace (min/km)
df_clean_running$pace <- round(60 / df_clean_running$speed, 4)
# Convert speed_max from meter-per-second to kilometer-per-hour
df_clean_running$speed_max <- round(df_clean_running$speed_max * 3.6, 4)
# Correction for max running speeds (remove the difference between speed and speed_max by half)
df_clean_running <- df_clean_running |> mutate(speed_max = speed_max - abs(speed - speed_max) * 0.5)
# Convert speed_max (km/h) to pace_max (min/km)
df_clean_running$pace_max <- 60 / df_clean_running$speed_max
##================================================================
##================================================================
## SECTION 0: Preparation
##================================================================
##================================================================
##########
## TODO ##
##########
# -
# -
# -
# Load packages
suppressPackageStartupMessages({
library(dplyr)
library(jsonlite)
library(httr)
library(ggplot2)
library(stringr)
library(tidyr)
library(purrr)
library(lubridate)
library(leaflet)
library(DT)
library(plotly)
library(openmeteo)
library(RColorBrewer)
})
# Prepare global environment
rm(list = ls(all = TRUE))
# Load existing data
#load("/Users/emmanueldockx/Dropbox/GitHub/emdockx.github.io/stravawattz.RData")
##================================================================
##================================================================
## SECTION 1: API and cleaning
##================================================================
##================================================================
# DEBUGGING
#df_running <- df_running[0, ]
#df_cycling <- df_cycling[0, ]
#df_swimming <- df_swimming[0, ]
#rm(list=setdiff(ls(), c("df_running", "df_cycling", "df_swimming")))
# Define Strava API credentials
STRAVA_KEY <- "113481"
STRAVA_SECRET <- "0195b39449a08d472051129f877d8279dfeeaaf7"
# Create an OAuth app
app <- oauth_app("strava", STRAVA_KEY, STRAVA_SECRET)
# Define the OAuth endpoints
endpoint <- oauth_endpoint(
request = NULL,
authorize = "https://www.strava.com/oauth/authorize",
access = "https://www.strava.com/oauth/token"
)
# Get an OAuth token
token <- oauth2.0_token(endpoint, app, as_header = FALSE, scope = "activity:read_all")
# Capture access token
access_token <- token$credentials$access_token
# Initialize empty dataframe
df <- data.frame()
# Initialize page variable
page <- 1
# Start data retrieval
while (TRUE) {
req <- httr::GET(
url = "https://www.strava.com/api/v3/athlete/activities",
config = token,
query = list(per_page = 200, page = page)
)
# Convert JSON to dataframe
activity_data <- fromJSON(content(req, as = "text"), flatten = TRUE)
# Stop if no data found
if (length(activity_data) == 0) {break}
# Append data while ensuring all columns are kept
df <- bind_rows(df, activity_data)
# Turn to next page
page <- page + 1
}
# Clean global environment
suppressWarnings({rm(app, endpoint, req, token, i, activity_data, common_cols, page, STRAVA_KEY, STRAVA_SECRET)})
# Determine useful existing data id's
#saved_id <- unique(c(df_running$id, df_cycling$id, df_swimming$id))
# Remove existing data
#df <- df |> filter(!(id %in% saved_id))
# Hier komt nog procedure om onnuttige id's op te slagen
# Proceed only if new data was found
if (nrow(df) >= 1) {
# Initialize empty geo column
df$geo <- NA
# Check each session for geo data
for (i in unique(df$id)){
temp <- df |> filter(id == i)
df$geo[match(i, df$id)] <- ifelse(any(sapply(temp$start_latlng, function(x) length(x) > 0)) == TRUE, 1, 0)}
# Filter and convert the raw data
df_clean <- df |>
select(id, date = start_date, type = sport_type, distance, time = moving_time, elevation = total_elevation_gain, speed = average_speed, speed_max = max_speed, hr = average_heartrate, hr_max = max_heartrate, geo) |>
mutate(date = as.Date(date), distance = round(distance, 0), time = round(time, 99), speed_max = speed_max, hr = round(hr, 0), hr_max = round(hr_max, 0)) |>
arrange(date, id, type, distance, time, elevation, hr)
# Cancel if no new data was found
} else {"No new Strava data found."}
#DEBUGGING
df_copy <- df
# Subset data
df_clean_running <- df_clean |> filter(type == "Run")
# Cleaning for RUNNING dataframe
df_clean_running <- df_clean_running |>
filter(geo == 1) |> # only when microdata is available
#filter(distance >= 1000) |> # only sessions with at least 1000m running
#filter(time >= 600) |> # only sessions with at least 10min running
filter(!is.na(hr)) |> # only sessions with non-missing HR data
arrange(id) # sort by id number
# Remove valid running sessions from df
df <- df[!(df$id %in% unique(df_clean_running$id)), ]
# Convert speed from meter-per-second to kilometer-per-hour
df_clean_running$speed <- round(df_clean_running$speed * 3.6, 4)
# Convert speed (km/h) to pace (min/km)
df_clean_running$pace <- round(60 / df_clean_running$speed, 4)
# Convert speed_max from meter-per-second to kilometer-per-hour
df_clean_running$speed_max <- round(df_clean_running$speed_max * 3.6, 4)
# Correction for max running speeds (remove the difference between speed and speed_max by half)
df_clean_running <- df_clean_running |> mutate(speed_max = speed_max - abs(speed - speed_max) * 0.5)
# Convert speed_max (km/h) to pace_max (min/km)
df_clean_running$pace_max <- 60 / df_clean_running$speed_max
unique(df_clean_running$id)
# Initialize a microdataframe
df_clean_running_temp <- data.frame()
View(df_clean_running_temp)
unique(df_clean_running$id)[1]
# Retrieve microdata
for (i in unique(df_clean_running$id)[1]){
url <- parse_url(str_glue("https://www.strava.com/api/v3/activities/{i}/streams"))
request <- modify_url(url, query = list(access_token = access_token, keys = str_glue("distance,time,latlng,altitude,velocity_smooth,cadence,watts,temp,moving,grade_smooth"))) |> GET()
stop_for_status(request)
temp <- fromJSON(content(request, as = "text"), flatten = TRUE) |> as_tibble() |> mutate(id = i)
df_clean_running_temp <- rbind(df_clean_running_temp, temp)
}
View(temp)
# Turn microdata in wide format
df_clean_running_temp <- pivot_wider(df_clean_running_temp, names_from = type, values_from = data)
# Clean microdata
df_clean_running_temp <- df_clean_running_temp |>
mutate(lat = map_if(.x = latlng, .p = ~ !is.null(.x), .f = ~ .x[, 1]),
lng = map_if(.x = latlng, .p = ~ !is.null(.x), .f = ~ .x[, 2])) |>
select(-c(latlng, original_size, resolution, series_type)) |>
unnest(where(is_list)) |>
rename(distance_cumulative = distance, time_cumulative = time)
# Combine all data
df_clean_running <- df_clean_running_temp |> left_join(df_clean_running, by = "id") |>
select(id, date, type, distance, time, elevation, hr, hr_max, speed, speed_max, pace, pace_max, geo, everything())
View(df_clean_running)
df_running <- data.frame()
df_running <- rbind(df_running, df_clean_running)
View(df_running)
i
url <- parse_url(str_glue("https://www.strava.com/api/v3/activities/{i}"))
request <- modify_url(url, query = list(access_token = access_token)) |> GET()
stop_for_status(request)
temp <- fromJSON(content(request, as = "text"), flatten = TRUE) |> as_tibble() |> mutate(id = i)
View(request)
View(request)
request[["date"]]
# Helper: Replace all NULLs with NAs recursively
null_to_na <- function(x) {
if (is.list(x)) {
lapply(x, null_to_na)
} else if (is.null(x)) {
NA
} else {
x
}
}
